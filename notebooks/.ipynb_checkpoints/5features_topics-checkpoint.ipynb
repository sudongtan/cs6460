{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://github.com/cemoody/lda2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "nltk.download('wordnet')\n",
    "from gensim import corpora\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "parser = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def find_topics(topic_scores):\n",
    "    topics = []\n",
    "    for topic, score in topic_scores:\n",
    "        if score >= 0.1:\n",
    "            topics.append(topic)\n",
    "    return topics\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dong/.conda/envs/reco_gpu/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "random.seed(333)\n",
    "text_data = []\n",
    "text = pd.read_csv('../data_raw/books_cleaned.csv')['summary']\n",
    "for line in text:\n",
    "    if type(line) == str:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        if random.random() > .99:\n",
    "            text_data.append(tokens)\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('../data_raw/corpus.pkl', 'wb'))\n",
    "dictionary.save('../data_raw/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dong/.conda/envs/reco_gpu/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/home/dong/.conda/envs/reco_gpu/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 15\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save(f'../models/model{NUM_TOPICS}.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"odette\" + 0.008*\"caesar\" + 0.007*\"series\" + 0.006*\"gordianus\" + 0.006*\"valdivia\"'),\n",
       " (1,\n",
       "  '0.009*\"mother\" + 0.007*\"family\" + 0.007*\"world\" + 0.005*\"lewis\" + 0.005*\"memoir\"'),\n",
       " (2,\n",
       "  '0.021*\"american\" + 0.013*\"religion\" + 0.009*\"meacham\" + 0.009*\"author\" + 0.008*\"founding\"'),\n",
       " (3,\n",
       "  '0.007*\"woman\" + 0.007*\"young\" + 0.007*\"victoria\" + 0.006*\"mother\" + 0.006*\"daughter\"'),\n",
       " (4,\n",
       "  '0.007*\"seven\" + 0.007*\"know\" + 0.007*\"history\" + 0.006*\"culture\" + 0.006*\"rufus\"'),\n",
       " (5,\n",
       "  '0.010*\"scott\" + 0.005*\"history\" + 0.005*\"journey\" + 0.005*\"young\" + 0.005*\"world\"'),\n",
       " (6,\n",
       "  '0.009*\"story\" + 0.007*\"woman\" + 0.006*\"years\" + 0.006*\"father\" + 0.006*\"family\"'),\n",
       " (7,\n",
       "  '0.010*\"woman\" + 0.009*\"world\" + 0.008*\"story\" + 0.006*\"mehrunnisa\" + 0.006*\"power\"'),\n",
       " (8,\n",
       "  '0.009*\"justin\" + 0.009*\"years\" + 0.008*\"nathaniel\" + 0.008*\"story\" + 0.007*\"series\"'),\n",
       " (9,\n",
       "  '0.009*\"adelia\" + 0.008*\"virgin\" + 0.008*\"business\" + 0.007*\"death\" + 0.007*\"richard\"'),\n",
       " (10,\n",
       "  '0.006*\"first\" + 0.006*\"family\" + 0.005*\"fight\" + 0.005*\"maggie\" + 0.005*\"american\"'),\n",
       " (11,\n",
       "  '0.010*\"woman\" + 0.006*\"edward\" + 0.006*\"story\" + 0.006*\"years\" + 0.004*\"first\"'),\n",
       " (12,\n",
       "  '0.010*\"family\" + 0.007*\"luling\" + 0.007*\"mackenzie\" + 0.007*\"romance\" + 0.006*\"catesby\"'),\n",
       " (13,\n",
       "  '0.011*\"prince\" + 0.010*\"modern\" + 0.008*\"sister\" + 0.008*\"charm\" + 0.008*\"monroe\"'),\n",
       " (14,\n",
       "  '0.009*\"church\" + 0.008*\"catholic\" + 0.006*\"young\" + 0.006*\"boleyn\" + 0.006*\"world\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract topics from the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data_raw/books_cleaned.csv')\n",
    "books['summary_new'] = books['summary'].apply(prepare_text_for_lda)\n",
    "books['summary_bow'] = books['summary_new'].apply(dictionary.doc2bow)\n",
    "books['topic_score'] = books['summary_bow'].apply(ldamodel.get_document_topics)\n",
    "books['topics'] = books['topic_score'].apply(find_topics)\n",
    "topics = []\n",
    "for t in books['topics']:\n",
    "    topics.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 10012, 10: 6297, 11: 5688, 7: 4813, 1: 4742, 14: 4553, 3: 3899, 9: 2754, 2: 2395, 4: 1842, 12: 1210, 0: 581, 8: 464, 5: 378, 13: 227})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(books['topics'].to_dict(), open('../data/book_idx_topics.json', 'w'))\n",
    "topic_book_idx = defaultdict(list)\n",
    "for book_idx, topics in books['topics'].to_dict().items():\n",
    "    for topic in topics:\n",
    "        topic_book_idx[topic].append(book_idx)\n",
    "json.dump(topic_book_idx, open('../data/topic_book_idx.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_gpu",
   "language": "python",
   "name": "reco_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
